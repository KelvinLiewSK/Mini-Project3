{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozx6Em55nVhE"
   },
   "source": [
    "# Goals of the notebook:\n",
    "    \n",
    "* Use Machine Learning models to train an NLP classifier to detect which class a text of a subreddit belong\n",
    "\n",
    "In this notebook, I will be doing the modelling part of the project. I will be trying 2 models:\n",
    "\n",
    "* RandomForestClassifier\n",
    "* Na√Øve Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L1lcoWSKmyfu"
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, make_scorer, accuracy_score, classification_report,f1_score,precision_score,recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "st9kSkzbNR6u",
    "outputId": "510f5922-c218-4df2-bca8-605aa51b01cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kelvin.liew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kelvin.liew\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyA8QCylJNsO"
   },
   "source": [
    "## Makeup Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "67cjEAsMnW-i"
   },
   "outputs": [],
   "source": [
    "# read makeup csv\n",
    "mkp_df = pd.read_csv('clean_makeup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "m0MbY5gRIubD",
    "outputId": "9fcbc579-aece-4ec6-eb34-5020c3f5ec9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Happy Feet Nourishment and Care[removed]</td>\n",
       "      <td>['Happy', 'Feet', 'Nourishment', 'and', 'Care'...</td>\n",
       "      <td>happy feet nourishment and care removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>What a long wearing foundation that looks flaw...</td>\n",
       "      <td>['What', 'long', 'wearing', 'foundation', 'tha...</td>\n",
       "      <td>what long wearing foundation that look flawles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Good blush colours for deep dark skin? (Nw58)S...</td>\n",
       "      <td>['Good', 'blush', 'colours', 'for', 'deep', 'd...</td>\n",
       "      <td>good blush colour for deep dark skin nw so try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Cruelty Free Concealer from Sephora. What bran...</td>\n",
       "      <td>['Cruelty', 'Free', 'Concealer', 'from', 'Seph...</td>\n",
       "      <td>cruelty free concealer from sephora what brand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Struggling to find a magenta/fuschia purple ey...</td>\n",
       "      <td>['Struggling', 'to', 'find', 'magenta', 'fusch...</td>\n",
       "      <td>struggling to find magenta fuschia purple eyes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                          full_text  \\\n",
       "1003    Makeup           Happy Feet Nourishment and Care[removed]   \n",
       "633     Makeup  What a long wearing foundation that looks flaw...   \n",
       "987     Makeup  Good blush colours for deep dark skin? (Nw58)S...   \n",
       "379     Makeup  Cruelty Free Concealer from Sephora. What bran...   \n",
       "57      Makeup  Struggling to find a magenta/fuschia purple ey...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1003  ['Happy', 'Feet', 'Nourishment', 'and', 'Care'...   \n",
       "633   ['What', 'long', 'wearing', 'foundation', 'tha...   \n",
       "987   ['Good', 'blush', 'colours', 'for', 'deep', 'd...   \n",
       "379   ['Cruelty', 'Free', 'Concealer', 'from', 'Seph...   \n",
       "57    ['Struggling', 'to', 'find', 'magenta', 'fusch...   \n",
       "\n",
       "                                                    lem  \n",
       "1003            happy feet nourishment and care removed  \n",
       "633   what long wearing foundation that look flawles...  \n",
       "987   good blush colour for deep dark skin nw so try...  \n",
       "379   cruelty free concealer from sephora what brand...  \n",
       "57    struggling to find magenta fuschia purple eyes...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check a sample of the data\n",
    "mkp_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3drcji10I2O4"
   },
   "outputs": [],
   "source": [
    "# rename the lem column\n",
    "mkp_df.rename(columns={'lem': 'clean_text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNlft4ntJRdJ"
   },
   "source": [
    "## Travel Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kUsuAynKJJlC"
   },
   "outputs": [],
   "source": [
    "#read fragrance csv\n",
    "trvl_df = pd.read_csv('clean_travel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "t-eQPn_BJY2l",
    "outputId": "3cb8c936-843c-465f-b7b9-dc163446ebcb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>travel</td>\n",
       "      <td>Advice for car renting in TurkeyHi r\\\\travel,\\...</td>\n",
       "      <td>['Advice', 'for', 'car', 'renting', 'in', 'Tur...</td>\n",
       "      <td>advice for car renting in turkeyhi travel plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>travel</td>\n",
       "      <td>One Of My Beautiful Moment On Hill.[removed]</td>\n",
       "      <td>['One', 'Of', 'My', 'Beautiful', 'Moment', 'On...</td>\n",
       "      <td>one of my beautiful moment on hill removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>travel</td>\n",
       "      <td>travelling to Bolivia this July and planning o...</td>\n",
       "      <td>['travelling', 'to', 'Bolivia', 'this', 'July'...</td>\n",
       "      <td>travelling to bolivia this july and planning o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>travel</td>\n",
       "      <td>Ibiza - but for mid 30's couple?Wife and I wen...</td>\n",
       "      <td>['Ibiza', 'but', 'for', 'mid', 'couple', 'Wife...</td>\n",
       "      <td>ibiza but for mid couple wife and went to ibiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>travel</td>\n",
       "      <td>Greece this Summer3 of us are heading to Greec...</td>\n",
       "      <td>['Greece', 'this', 'Summer', 'of', 'us', 'are'...</td>\n",
       "      <td>greece this summer of u are heading to greece ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                          full_text  \\\n",
       "860    travel  Advice for car renting in TurkeyHi r\\\\travel,\\...   \n",
       "64     travel       One Of My Beautiful Moment On Hill.[removed]   \n",
       "749    travel  travelling to Bolivia this July and planning o...   \n",
       "463    travel  Ibiza - but for mid 30's couple?Wife and I wen...   \n",
       "136    travel  Greece this Summer3 of us are heading to Greec...   \n",
       "\n",
       "                                                tokens  \\\n",
       "860  ['Advice', 'for', 'car', 'renting', 'in', 'Tur...   \n",
       "64   ['One', 'Of', 'My', 'Beautiful', 'Moment', 'On...   \n",
       "749  ['travelling', 'to', 'Bolivia', 'this', 'July'...   \n",
       "463  ['Ibiza', 'but', 'for', 'mid', 'couple', 'Wife...   \n",
       "136  ['Greece', 'this', 'Summer', 'of', 'us', 'are'...   \n",
       "\n",
       "                                                   lem  \n",
       "860  advice for car renting in turkeyhi travel plan...  \n",
       "64          one of my beautiful moment on hill removed  \n",
       "749  travelling to bolivia this july and planning o...  \n",
       "463  ibiza but for mid couple wife and went to ibiz...  \n",
       "136  greece this summer of u are heading to greece ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvl_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1ULTRgC9JhOp"
   },
   "outputs": [],
   "source": [
    "trvl_df.rename(columns={'lem': 'clean_text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5kwfk-bJpeX"
   },
   "source": [
    "## Data preprocessing\n",
    "In this step we will combine both dataframes in order to build a one dataframe with texts data from both classes `travel` and `makeup` for modeling stages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cn2W8prwJlki"
   },
   "outputs": [],
   "source": [
    "# combining the 2 dataframes together into 1 datatframe called df\n",
    "frames = [trvl_df, mkp_df]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eMV-5mEoKAgU",
    "outputId": "2c2f331b-acb1-4f38-b4f6-406e9d346e09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>eyeshadow as eyelinerso I‚Äôve recently found th...</td>\n",
       "      <td>['eyeshadow', 'as', 'eyelinerso', 've', 'recen...</td>\n",
       "      <td>eyeshadow a eyelinerso ve recently found that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Moisturizer pills upNot sure if this is an app...</td>\n",
       "      <td>['Moisturizer', 'pills', 'upNot', 'sure', 'if'...</td>\n",
       "      <td>moisturizer pill upnot sure if this is an appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>travel</td>\n",
       "      <td>Hey, can anyone recommend a travel bag for int...</td>\n",
       "      <td>['Hey', 'can', 'anyone', 'recommend', 'travel'...</td>\n",
       "      <td>hey can anyone recommend travel bag for interr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Moisturizer leaves face shinyHello! I currentl...</td>\n",
       "      <td>['Moisturizer', 'leaves', 'face', 'shinyHello'...</td>\n",
       "      <td>moisturizer leaf face shinyhello currently do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>Help with concealer on undereyesApologies if t...</td>\n",
       "      <td>['Help', 'with', 'concealer', 'on', 'undereyes...</td>\n",
       "      <td>help with concealer on undereyesapologies if t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                          full_text  \\\n",
       "1044    Makeup  eyeshadow as eyelinerso I‚Äôve recently found th...   \n",
       "757     Makeup  Moisturizer pills upNot sure if this is an app...   \n",
       "428     travel  Hey, can anyone recommend a travel bag for int...   \n",
       "1204    Makeup  Moisturizer leaves face shinyHello! I currentl...   \n",
       "123     Makeup  Help with concealer on undereyesApologies if t...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1044  ['eyeshadow', 'as', 'eyelinerso', 've', 'recen...   \n",
       "757   ['Moisturizer', 'pills', 'upNot', 'sure', 'if'...   \n",
       "428   ['Hey', 'can', 'anyone', 'recommend', 'travel'...   \n",
       "1204  ['Moisturizer', 'leaves', 'face', 'shinyHello'...   \n",
       "123   ['Help', 'with', 'concealer', 'on', 'undereyes...   \n",
       "\n",
       "                                             clean_text  \n",
       "1044  eyeshadow a eyelinerso ve recently found that ...  \n",
       "757   moisturizer pill upnot sure if this is an appr...  \n",
       "428   hey can anyone recommend travel bag for interr...  \n",
       "1204  moisturizer leaf face shinyhello currently do ...  \n",
       "123   help with concealer on undereyesapologies if t...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking 1st 5 rows of df\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81OEKKAeKJvx"
   },
   "source": [
    "in the next coming steps, we won't be using the other 2 columns `full_text` and `tokens` so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Czj3K9rsKETR"
   },
   "outputs": [],
   "source": [
    "data.drop(['full_text', 'tokens'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8dfnDpnKhIq"
   },
   "source": [
    "In this step, we will build a function that gonna preprocess our data to be prepared for machine learning model, the features included in this preprocessing stage are :\n",
    "\n",
    "1. Lowercase text  \n",
    "2. Remove whitespace  \n",
    "3. Remove numbers  \n",
    "4. Remove special characters  \n",
    "5. Remove emails  \n",
    "6. Remove stop words \n",
    "7. Remove NAN  \n",
    "8. Remove weblinks  \n",
    "9. Expand contractions (if possible not necessary)  \n",
    "10. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iJK-ZO1jMiVY"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "99XrJsR9KWYu"
   },
   "outputs": [],
   "source": [
    "def preprocess(clean_text):\n",
    "    # lowercase text\n",
    "    clean_text = str(clean_text)\n",
    "    clean_text = clean_text.lower() \n",
    "    # remove html tags\n",
    "    clean_text = clean_text.replace('{html}',\"\")           \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    clean_text = re.sub(cleanr, '', clean_text)\n",
    "    # remove url\n",
    "    rem_url = re.sub(r'http\\S+', '',clean_text)\n",
    "    # remove numbers\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    # filter stopwords\n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sbWq41MpMrjO"
   },
   "outputs": [],
   "source": [
    "data['clean_message'] = data['clean_text'].apply(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VwP5x2F6NPzM",
    "outputId": "feb3c172-8c11-4fcd-f179-cc828136a0f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>salvation removed</td>\n",
       "      <td>salvation removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>am available for hookup hmu on hangout now cla...</td>\n",
       "      <td>available hookup hmu hangout clarakimber gmail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>f4m bored and horny at home wanna get fuck sna...</td>\n",
       "      <td>bored horny home wanna get fuck snap jullianke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>rare beauty positive light tinted moisturizer ...</td>\n",
       "      <td>rare beauty positive light tinted moisturizer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>Makeup</td>\n",
       "      <td>does anyone here struggle to put on lipstick h...</td>\n",
       "      <td>anyone struggle put lipstick hello research pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                         clean_text  \\\n",
       "619     Makeup                                  salvation removed   \n",
       "818     Makeup  am available for hookup hmu on hangout now cla...   \n",
       "717     Makeup  f4m bored and horny at home wanna get fuck sna...   \n",
       "547     Makeup  rare beauty positive light tinted moisturizer ...   \n",
       "1227    Makeup  does anyone here struggle to put on lipstick h...   \n",
       "\n",
       "                                          clean_message  \n",
       "619                                   salvation removed  \n",
       "818   available hookup hmu hangout clarakimber gmail...  \n",
       "717   bored horny home wanna get fuck snap jullianke...  \n",
       "547   rare beauty positive light tinted moisturizer ...  \n",
       "1227  anyone struggle put lipstick hello research pr...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iqxHZFsWNeI_"
   },
   "outputs": [],
   "source": [
    "# selecting the necessary columns into df\n",
    "data = data[['subreddit', 'clean_message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MgZic8QKN2P9"
   },
   "outputs": [],
   "source": [
    "# save the cleaned df to csv\n",
    "data.to_csv('cleaned_subreddit.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ9MqWDKN-g6"
   },
   "source": [
    "# Converting our subreddit column:  \n",
    "\n",
    "Converting makeup/travel into binary labels    \n",
    "* 0 stands for travel  \n",
    "* 1 stands for makeup  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YCvqEfxfN4s5"
   },
   "outputs": [],
   "source": [
    "data['subreddit'] = data['subreddit'].map({'travel':0, 'Makeup':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TqiluCTCOOHg",
    "outputId": "2b4c5b78-0d39-4cd3-e58d-851b0bc1d4ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>1</td>\n",
       "      <td>literally nothing cover dark circlesi use colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>1</td>\n",
       "      <td>survey removed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>sun day makeup helpi work long hour day sun le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1</td>\n",
       "      <td>becca mineral blush flowerchild laura mercier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1</td>\n",
       "      <td>makeup product make eye tear upas title say bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                      clean_message\n",
       "1249          1  literally nothing cover dark circlesi use colo...\n",
       "964           1                                     survey removed\n",
       "97            1  sun day makeup helpi work long hour day sun le...\n",
       "1073          1  becca mineral blush flowerchild laura mercier ...\n",
       "292           1  makeup product make eye tear upas title say bu..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y7cTgeCdOPFD",
    "outputId": "402c79b3-e8f7-423f-e2b3-d4c1520d30e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1369\n",
       "0     973\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkVojTj7OXLl"
   },
   "source": [
    "I did a value count to ensure there is no data imbalance. As we can see, the subreddits have slightly a gap of 430 rows. Hence we are going to rebalance the data by undersamling the most dominated subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Gmsp5RmGOTY-"
   },
   "outputs": [],
   "source": [
    "def sampling_k_elements(group, k=946):\n",
    "    if len(group) < k:\n",
    "        return group\n",
    "    return group.sample(k)\n",
    "\n",
    "balanced_df = data.groupby('subreddit').apply(sampling_k_elements).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1xq_8Z8Qqkg",
    "outputId": "6c942a8e-623f-4f0d-d81c-6e4745678b93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    946\n",
       "1    946\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uc2tiZ84R_oR"
   },
   "source": [
    "# Modelling\n",
    "Cross-validation is a common method to evaluate the performance of a text classifier. It works by splitting the training dataset into random, equal-length example sets( in this case, we have 70% training set and 30% test set). For each set, a text classifier is trained with the remaining samples. Next, the classifiers make predictions on their respective sets, and the results are compared against the human-annotated tags. This will determine when a prediction was right (true positives and true negatives) and when it made a mistake (false positives, false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "K7ehS211RiIs"
   },
   "outputs": [],
   "source": [
    "X = balanced_df['clean_message']\n",
    "y = balanced_df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XY1DEbxjSUuA"
   },
   "source": [
    "## Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aWxHJdfUSPA7"
   },
   "outputs": [],
   "source": [
    "# split the data into the training and testing sets with 70% training set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVXfbZSCSZEA",
    "outputId": "7b0a0801-6333-498d-b65e-a47567696661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset has 1324 rows and the test set has 568 rows\n"
     ]
    }
   ],
   "source": [
    "print(f\"The training dataset has {X_train.shape[0]} rows and the test set has {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm_3oBZ9U0vH"
   },
   "source": [
    "# Baseline Model: RandomForestClassifier\n",
    "### RandomForestClassifier: \n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
    "\n",
    "### Count Vectorization\n",
    "It converts a collection of text documents to a matrix of token counts. \n",
    "\n",
    "### Pipeline\n",
    "I am using a pipeline with CountVectorizer & RandomForest Classifier in order to search through a few parameters that I have picked so that I am able to get a better results from a series of parameters.\n",
    "\n",
    "For count vectorization, the parameters that I will be searching through are:\n",
    "\n",
    "* stop_words: {‚Äòenglish‚Äô} or none. However, I have already dropped certain words earlier that I do not want to include in modelling. \n",
    "* min_df : minimum number of documents needed to include tokens: 2,3\n",
    "* max_df: If a word occurs in more than 0.9 or 0.95, it will get removed.\n",
    "* n_gram_range: For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 3) means bigrams and trigram.\n",
    "* n_estimators: number of trees in a forest\n",
    "* max_depth:The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. I have decided to try a total of 7 variables as I do not wish for my classifier to take too long to get results.  \n",
    "\n",
    "### Scoring\n",
    "* AUC & Accuracy is used. There are many other scoring metrics that can be used such as recall, precision and F1. But I have decided to just use 2 metrics as the problem statement is to classify the reddit post to its proper subreddit category.Also, since my data is balanced and weighing the objective of the project, I can safely rely on accuracy score. Hence, I believe that these 2 metrics are sufficient to tell us if our end results are good and the objective has been met. \n",
    "\n",
    "* AUC: The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes. if the AUC is closer to 1, it means that the performance of the model is more accurate at distinguishing between the positive and negative classes.\n",
    "\n",
    "* Accuracy: Accuracy represents the number of correctly classified data instances over the total number of data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1ifKTNAKUwQU"
   },
   "outputs": [],
   "source": [
    "pipe  = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "F6aI0ed-VoGm"
   },
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [900, 1_000],\n",
    "    'cvec__stop_words': [\"english\"],\n",
    "    'cvec__min_df': [2, 3],\n",
    "    'cvec__max_df': [.9],\n",
    "    'cvec__ngram_range': [(1, 1),(1, 2)],\n",
    "    'rf__n_jobs': [-1],\n",
    "    'rf__n_estimators': [100,150,200],\n",
    "    'rf__max_depth': [4, 5, 6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RAoM7kEkVqfn"
   },
   "outputs": [],
   "source": [
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Knv9gonMVzQx"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rSH6wgwQV2ho"
   },
   "outputs": [],
   "source": [
    "# instantiate GridSeachCV\n",
    "gs = GridSearchCV(pipe, param_grid = pipe_params, cv = 3, scoring = scorers, n_jobs = -1, refit = 'AUC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNsNyVtYV50e",
    "outputId": "9ff67830-7667-4b12-c262-fa03953bc719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9],\n",
       "                         'cvec__max_features': [900, 1000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'rf__max_depth': [4, 5, 6],\n",
       "                         'rf__n_estimators': [100, 150, 200],\n",
       "                         'rf__n_jobs': [-1]},\n",
       "             refit='AUC',\n",
       "             scoring={'AUC': 'roc_auc',\n",
       "                      'Accuracy': make_scorer(accuracy_score)})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit grid search to training data\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_7rf2J1V9AS",
    "outputId": "083d5c2b-eb16-4372-8356-7ea3a53ff222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:28.965602\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFE7VittcpND",
    "outputId": "8c0d3aa0-85c2-4f61-946e-ef2844c0008f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9686074191628645"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score model on test set\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFdBk6V6eP_a",
    "outputId": "80f7598b-4ed2-4457-e50d-bc9e5ca4a04f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 900,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rf__max_depth': 6,\n",
       " 'rf__n_estimators': 200,\n",
       " 'rf__n_jobs': -1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best params\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "hC00ZwN1eUMW"
   },
   "outputs": [],
   "source": [
    "#get predictions\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "#save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "22tpuyD9euDJ",
    "outputId": "febfbaab-54bd-4c40-9ab8-73cbd9aeb601"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View confusion matrix\n",
    "plot_confusion_matrix(gs, X_test, y_test, cmap='PuRd', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILLd-bgje8Bi"
   },
   "source": [
    "Specificity (SP) is calculated as the number of correct negative predictions divided by the total number of negatives. It is also called true negative rate (TNR). The best specificity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loxnXXVlext-",
    "outputId": "43c4f7bc-fe2d-4e5b-d9b0-24b1b4719939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9964788732394366\n"
     ]
    }
   ],
   "source": [
    "# Calculate the specificity\n",
    "spec = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNFCEJ-7fPOM"
   },
   "source": [
    "Recall is also known as sensitivity or true positive rate. Recall should ideally be 1 (high) for a good classifier. Recall becomes 1 only when the numerator and denominator are equal i.e TP = TP +FN, this also means FN is zero. As FN increases the value of denominator becomes greater than the numerator and recall value decreases (which we don‚Äôt want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VhJxZTOfMAF",
    "outputId": "1704709b-2774-4188-de87-318a7cff8ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7992957746478874\n"
     ]
    }
   ],
   "source": [
    "# Calculate the recall\n",
    "recall_rf = tp / (tp + fn)\n",
    "\n",
    "print('Recall:', recall_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Kj45rb88fTkG"
   },
   "outputs": [],
   "source": [
    "#RandomForest AUC/Accuracy Score\n",
    "rf_auc_train = gs.score(X_train,y_train)\n",
    "rf_auc_test = gs.score(X_test,y_test)\n",
    "rf_acc_train = accuracy_score(gs.predict(X_train),y_train)\n",
    "rf_acc_test = accuracy_score(gs.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4VNuta5fWCf",
    "outputId": "583d4f51-15ee-428b-ced0-f12d2a8e659d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest AUC train score 0.9786100893566141\n",
      "RandomForest AUC test score 0.9686074191628645\n",
      "RandomForest Accuracy train score 0.9123867069486404\n",
      "RandomForest Accuracy test score 0.897887323943662\n"
     ]
    }
   ],
   "source": [
    "print(f'RandomForest AUC train score {rf_auc_train}')\n",
    "print(f'RandomForest AUC test score {rf_auc_test}')\n",
    "print(f'RandomForest Accuracy train score {rf_acc_train}')\n",
    "print(f'RandomForest Accuracy test score {rf_acc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbTAFVZLf1CQ"
   },
   "source": [
    "## Naive Bayes classifier\n",
    "Naive Bayes is a family of probabilistic algorithms that take advantage of probability theory and Bayes‚Äô Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes‚Äô Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sDIYVj2ofYBY"
   },
   "outputs": [],
   "source": [
    "#Creating Pipeline for Naive Bayes Model\n",
    "pipe2 = Pipeline([(\"vec\", None), (\"model\", MultinomialNB())])\n",
    "\n",
    "param_grid2 = {\"vec\": [CountVectorizer(), TfidfVectorizer()],\n",
    "              'vec__max_features': [800, 900, 1_000],\n",
    "              'vec__stop_words': [\"english\"],\n",
    "              'vec__min_df': [2, 3],\n",
    "              'vec__max_df': [.9, .95],\n",
    "              'vec__ngram_range': [(1, 1),(1, 2)],     \n",
    "             }\n",
    "\n",
    "#gs = GridSearchCV(pipe_tvec, param_grid = pipe_tvec_params, cv=5) \n",
    "scorers = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "gs_nb = GridSearchCV(pipe2, param_grid2,cv = 3, scoring = scorers,refit = 'AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5de5ukejgELU",
    "outputId": "4c69a8c4-721c-4e49-f8f1-98145dfd2cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:11.128087\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "#Fitting Pipeline into GridSearchCV\n",
    "gs_nb.fit(X_train, y_train)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QMbxjnDgKz7",
    "outputId": "04894508-e645-4c6c-89e1-d0b344e7e59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927283773060901"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score model on test set\n",
    "gs_nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsfex_pIgpDS",
    "outputId": "0a31d983-556a-43d9-cf62-82ce2f1beda1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec': CountVectorizer(max_df=0.9, max_features=1000, min_df=3, stop_words='english'),\n",
       " 'vec__max_df': 0.9,\n",
       " 'vec__max_features': 1000,\n",
       " 'vec__min_df': 3,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the best params\n",
    "gs_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "TeIon9apgsdt"
   },
   "outputs": [],
   "source": [
    "#get predictions\n",
    "preds2 = gs_nb.predict(X_test)\n",
    "\n",
    "#save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "DHNmWsg6gugf",
    "outputId": "3f4d02be-9f66-4c90-8023-1d713eb54499"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View confusion matrix\n",
    "plot_confusion_matrix(gs_nb, X_test, y_test, cmap='PuRd', values_format='d');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Meb0RTizgziH"
   },
   "source": [
    "Specificity (SP) is calculated as the number of correct negative predictions divided by the total number of negatives. It is also called true negative rate (TNR). The best specificity is 1.0, whereas the worst is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3yqIMy7WgwLh",
    "outputId": "d3613f65-cefb-4d7b-e117-8c182202f392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "# Calculate the specificity\n",
    "spec_nb = tn / (tn + fp)\n",
    "\n",
    "print('Specificity:', spec_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iN8MFPxDg-dn"
   },
   "source": [
    "Recall is also known as sensitivity or true positive rate. Recall should ideally be 1 (high) for a good classifier. Recall becomes 1 only when the numerator and denominator are equal i.e TP = TP +FN, this also means FN is zero. As FN increases the value of denominator becomes greater than the numerator and recall value decreases (which we don‚Äôt want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5msMA4dRg75w",
    "outputId": "66fcc751-2783-4197-c8a5-2e3a837ed35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9014084507042254\n"
     ]
    }
   ],
   "source": [
    "# Calculate the recall\n",
    "recall_nb = tp / (tp + fn)\n",
    "\n",
    "print('Recall:', recall_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "3JoIywSqhBNk"
   },
   "outputs": [],
   "source": [
    "# AUC/Accuracy Score\n",
    "aucnb_train = gs_nb.score(X_train,y_train)\n",
    "aucnb_test = gs_nb.score(X_test,y_test)\n",
    "accnb_train = accuracy_score(gs_nb.predict(X_train),y_train)\n",
    "accnb_test = accuracy_score(gs_nb.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXVtSkROhC-s",
    "outputId": "dec055c5-897c-4eb5-9bb2-d1f8dd31d466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes AUC train score 0.9969834156314747\n",
      "Naive Bayes AUC test score 0.9927283773060901\n",
      "Naive Bayes Accuracy train score 0.9622356495468278\n",
      "Naive Bayes Accuracy test score 0.9436619718309859\n"
     ]
    }
   ],
   "source": [
    "print(f'Naive Bayes AUC train score {aucnb_train}')\n",
    "print(f'Naive Bayes AUC test score {aucnb_test}')\n",
    "print(f'Naive Bayes Accuracy train score {accnb_train}')\n",
    "print(f'Naive Bayes Accuracy test score {accnb_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smWqhJoghEOf",
    "outputId": "b2ad087b-b414-4822-90f4-253bd188a11e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes AUC train score 0.9969834156314747\n",
      "Naive Bayes AUC test score 0.9927283773060901\n",
      "Naive Bayes Accuracy train score 0.9622356495468278\n",
      "Naive Bayes Accuracy test score 0.9436619718309859\n",
      "Naive Bayes Specificity 0.9859154929577465\n",
      "Naive Bayes Recall 0.9014084507042254\n",
      "----------------------------------------------\n",
      "\n",
      "RandomForest AUC train score 0.9786100893566141\n",
      "RandomForest AUC test score 0.9686074191628645\n",
      "RandomForest Accuracy train score 0.9123867069486404\n",
      "RandomForest Accuracy test score 0.897887323943662\n",
      "RandomForest Specificity 0.9964788732394366\n",
      "RandomForest Recall 0.7992957746478874\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Naive Bayes AUC train score {aucnb_train}')\n",
    "print(f'Naive Bayes AUC test score {aucnb_test}')\n",
    "print(f'Naive Bayes Accuracy train score {accnb_train}')\n",
    "print(f'Naive Bayes Accuracy test score {accnb_test}')\n",
    "print(f'Naive Bayes Specificity {spec_nb}')\n",
    "print(f'Naive Bayes Recall {recall_nb}')\n",
    "print('----------------------------------------------')\n",
    "print('')\n",
    "print(f'RandomForest AUC train score {rf_auc_train}')\n",
    "print(f'RandomForest AUC test score {rf_auc_test}')\n",
    "print(f'RandomForest Accuracy train score {rf_acc_train}')\n",
    "print(f'RandomForest Accuracy test score {rf_acc_test}')\n",
    "print(f'RandomForest Specificity {spec}')\n",
    "print(f'RandomForest Recall {recall_rf}')\n",
    "print('----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bl1AhegkhG0n",
    "outputId": "71aa287d-873e-4100-c670-9678fef09025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff in NB AUC score 0.004255038325384652\n",
      "Diff in NB accuracy score 0.018573677715841952\n",
      "----------------------------------------------\n",
      "\n",
      "Diff in RF AUC score 0.010002670193749563\n",
      "Diff in RF accuracy score 0.014499383004978439\n"
     ]
    }
   ],
   "source": [
    "print(f'Diff in NB AUC score {aucnb_train - aucnb_test }')\n",
    "print(f'Diff in NB accuracy score {accnb_train - accnb_test }')\n",
    "print('----------------------------------------------')\n",
    "print('')\n",
    "print(f'Diff in RF AUC score {rf_auc_train - rf_auc_test }')\n",
    "print(f'Diff in RF accuracy score {rf_acc_train - rf_acc_test }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_5Ug-0HhQXC"
   },
   "source": [
    "# Conclusion, Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uU6Sc-MwhS18"
   },
   "source": [
    "####  Both models are able to classify which subreddit a post has been given to.\n",
    "    \n",
    "           \n",
    "####  Best model recommendation: Naive Bayes        \n",
    "     \n",
    "    * difference between the test/training AUC score and accuracy score is less than 0.0011\n",
    "    * AUC score and accuracy score is also the highest\n",
    "    * Lower false negative and false positive\n",
    "    * Higher Recall(True Positive rate)   \n",
    "         \n",
    "\n",
    "####  Best Parameters for NB:\n",
    "```{'vec': CountVectorizer(max_df=0.9, max_features=800, min_df=2, ngram_range=(1, 2),\n",
    "                 stop_words='english'),\n",
    " 'vec__max_df': 0.9,\n",
    " 'vec__max_features': 800,\n",
    " 'vec__min_df': 2,\n",
    " 'vec__ngram_range': (1, 2),\n",
    " 'vec__stop_words': 'english'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ2u8ENPh3UU"
   },
   "source": [
    "#### Future Steps:\n",
    "* Explore with other different models\n",
    "* Select features that are important and see if it can give a better results\n",
    "* Explore more with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDGwyulYhL_7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
